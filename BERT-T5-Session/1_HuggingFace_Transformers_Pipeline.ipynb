{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Transformer pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Transformers\n",
    "Transformers is a core deep learning module behind the success of recent AI models.\n",
    "\n",
    "<img src=\"images/transformers.png\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"images/hugging_face.png\" width=\"40\" height=\"40\"> Introduction to Hugging Face\n",
    "- Hugging Face is a company that focuses on natural language processing (NLP) and provides various tools and libraries to facilitate NLP tasks. One of their popular offerings is the Transformers library.\n",
    "- [Hugging Face website](https://huggingface.co/)\n",
    "\n",
    "### Transformers Library\n",
    "- The Transformers library is a powerful and easy-to-use library for applying state-of-the-art NLP models to various tasks. \n",
    "- It provides pre-trained models for tasks like text classification, named entity recognition, question answering, and more.\n",
    "\n",
    "### Hugging Face Hub\n",
    "\n",
    "- Hugging Face Hub is a platform provided by Hugging Face where you can find a wide range of pre-trained models and datasets. \n",
    "- It allows you to easily access and use these models and datasets in your own projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (4.49.0)\n",
      "Requirement already satisfied: gradio in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (5.20.0)\n",
      "Requirement already satisfied: filelock in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.115.11)\n",
      "Requirement already satisfied: ffmpy in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.2 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (1.7.2)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (2.10.6)\n",
      "Requirement already satisfied: pydub in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.9.9)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.46.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio-client==1.7.2->gradio) (2024.12.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from gradio-client==1.7.2->gradio) (15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/kevin/miniconda3/envs/bert-handson-env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Let's install the transformers library using pip\n",
    "! pip install transformers gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Pipeline\n",
    "\n",
    "The Hugging Face Pipeline is a high-level API that provides a simple and convenient way to use pre-trained models for various NLP tasks. It abstracts away the complexities of model loading, tokenization, and inference, allowing you to focus on the task at hand.\n",
    "\n",
    "With the Hugging Face Pipeline, you can perform tasks such as text generation, sentiment analysis, named entity recognition, question answering, and more, with just a few lines of code.\n",
    "\n",
    "\n",
    "<img src=\"images/pipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation task pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf47ef3ce4441d2b2c23898510ee237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f2b2fd9e6a4939bac1d0bcf9339481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85387dc50c2b45d9bbf89a0d632bc48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f126dae9964741a0db8e7325a5e88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8cebb4cebd4c759301377bf7a0f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162861fb76bd4744baa8bb93de560d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90edf0104674cf2baedc6ef412172c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b8b6d6831647ac94c719d430ba0a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-135M\") # device=0 means use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = pipe('''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def print_prime(n):\n",
      "   \"\"\"\n",
      "   Print all primes between 1 and n\n",
      "   \"\"\"\n",
      "   if n <= 1:\n",
      "      return\n",
      "   for i in range(2, int(n**0.5)+1):\n",
      "      if n % i == 0:\n",
      "         return False\n",
      "   return True\n",
      "\n",
      "def is_prime(n):\n",
      "   \"\"\"\n",
      "   Returns True if n is a prime number\n",
      "   \"\"\"\n",
      "   if n == 1:\n",
      "      return False\n",
      "   if n == \n"
     ]
    }
   ],
   "source": [
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5564454f9c394a1ab9dfdadf9497dae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4785d00955a45d68922744d744e3108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e27355af28641e28ce78f1997bb2e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c53f8bdff040eaa4d6803f80378053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\") # If you don't specify a model, it will use the default one\n",
    "classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert/distilbert-base-uncased-finetuned-sst-2-english'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model.name_or_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image captioning task pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c568bcfde0476f8405919404ca749d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d37ec57626422d9e30c56b8f82e11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf1c6a9bfb64229a09c9ad1770b0c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c54bc4fe2f4a42847133f28ecf7431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb11786ca8d64309bb7b74c18e8d3b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23770ca8f2d34dfba085b2f4ab3a1c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355fd254b71749d4915441f35088af40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1b50f452c74eeda4af1186b608fb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'tom and jerry'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_text = pipeline(task=\"image-to-text\", device=0, model=\"Salesforce/blip-image-captioning-base\")\n",
    "img_to_text(\"images/tom_jerry.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Missing file: /usr/local/lib/python3.12/site-packages/gradio/frpc_linux_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64\n",
      "2. Rename the downloaded file to: frpc_linux_amd64_v0.3\n",
      "3. Move the file to this location: /usr/local/lib/python3.12/site-packages/gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "gr.Interface.from_pipeline(img_to_text).launch(debug=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
