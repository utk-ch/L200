{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModernBERT\n",
    "\n",
    "BERT is an ancient (given the speed of innovation) model. While it has proven to be useful in multiple places, it has (relative) shortcomings. ModernBert takes all the recent advances in the area and applies them to BERT-style model.\n",
    "\n",
    "1. Architectural changes:\n",
    "    1. Rotary Positional Encodings\n",
    "    2. GeGLU instead of MLP layers\n",
    "    3. Extra normalization layer after embeddings\n",
    "    4. Alternating Global and Local attention layers\n",
    "2. Training Data:\n",
    "    2 Trillion tokens of highly diverse data\n",
    "3. Training process:\n",
    "    3 phases:\n",
    "    1. 1.7 trillion tokens at a sequence length of 1024\n",
    "    2. Long-context adaption phase: 250 billion tokens at sequence length of 8192\n",
    "    3. Annealing on 50 billion tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"answerdotai/ModernBERT-base\",\n",
    "                                            #  attn_implementation=\"flash_attention_2\", \n",
    "                                             torch_dtype=torch.float16)\n",
    "# model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASK token id: 50284\n",
      "{'input_ids': tensor([[50281,    42,  1663, 50284,   253,  6440,    15,   733,   369,  3240,\n",
      "          4722,    15, 50282]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "torch.Size([50368])\n",
      "Ġliked\n"
     ]
    }
   ],
   "source": [
    "text = \"I really [MASK] the movie. It was quite interesting.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "print(f\"MASK token id: {tokenizer.mask_token_id}\")\n",
    "print(inputs)\n",
    "\n",
    "for key in inputs:\n",
    "    # inputs[key] = inputs[key].to('cuda')\n",
    "    inputs[key] = inputs[key]\n",
    "\n",
    "output = model(**inputs)\n",
    "\n",
    "print(output['logits'][0, 3].shape)\n",
    "predicted_index = output['logits'][0,3].argmax()\n",
    "\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASK token id: 50284\n",
      "{'input_ids': tensor([[50281,    42,  1663, 50284,   253,  6440,    15,   733,   369, 11216,\n",
      "           285, 22258,    15, 50282]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "torch.Size([50368])\n",
      "Ġhated\n"
     ]
    }
   ],
   "source": [
    "text = \"I really [MASK] the movie. It was loud and boring.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "print(f\"MASK token id: {tokenizer.mask_token_id}\")\n",
    "print(inputs)\n",
    "\n",
    "for key in inputs:\n",
    "    # inputs[key] = inputs[key].to('cuda')\n",
    "    inputs[key] = inputs[key]\n",
    "\n",
    "output = model(**inputs)\n",
    "\n",
    "print(output['logits'][0, 3].shape)\n",
    "predicted_index = output['logits'][0,3].argmax()\n",
    "\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning using HF Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m device = \u001b[43mtorch\u001b[49m.device(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"fancyzhx/ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=100, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tokenized_dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 3,  ..., 1, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'World': 0, 'Sports': 1, 'Business': 2, 'Sci/Tech': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", \n",
    "                                                           attn_implementation=\"flash_attention_2\", \n",
    "                                                           torch_dtype=torch.bfloat16,\n",
    "                                                           num_labels=len(label2id),\n",
    "                                                           label2id=label2id,\n",
    "                                                           id2label=id2label\n",
    "                                                           )\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "#                                                            num_labels=2,\n",
    "#                                                         #    label2id=label2id,\n",
    "#                                                         #    id2label=id2label\n",
    "#                                                            )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_dir = \"./test-api-finetuning/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = output_model_dir,\n",
    "    per_device_train_batch_size = 64,\n",
    "    per_device_eval_batch_size = 32,\n",
    "    learning_rate = 5e-5,\n",
    "    num_train_epochs = 2,\n",
    "    bf16 = True, # bfloat16 training \n",
    "    optim = \"adamw_torch_fused\", # improved optimizer \n",
    "    # logging & evaluation strategies\n",
    "    logging_strategy = \"steps\",\n",
    "    logging_steps = 100,\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    save_total_limit = 2,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"f1\",\n",
    "    # push to hub parameters\n",
    "    push_to_hub = False,\n",
    "    report_to=\"none\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis = 1)\n",
    "    score = f1_score(labels, predictions, average='macro')\n",
    "    return {\"f1\": float(score) if score == 1 else score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_loss(eval_pred, num_items_in_batch):\n",
    "#     logits, labels = eval_pred\n",
    "#     loss_fct = torch.nn.CrossEntropyLoss()\n",
    "#     return loss_fct(logits.view(-1, num_labels), labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset[\"train\"].select(range(10000)),\n",
    "    eval_dataset = tokenized_dataset[\"test\"].select(range(100)),\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='314' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [314/314 01:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.676900</td>\n",
       "      <td>0.372692</td>\n",
       "      <td>0.833167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.330427</td>\n",
       "      <td>0.857928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.335434</td>\n",
       "      <td>0.848628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the best model at ./test-api-finetuning/checkpoint-200/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=314, training_loss=0.48316904693652113, metrics={'train_runtime': 68.1225, 'train_samples_per_second': 293.589, 'train_steps_per_second': 4.609, 'total_flos': 1331103792000000.0, 'train_loss': 0.48316904693652113, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = trainer.predict(tokenized_dataset[\"test\"].select(range(100)))\n",
    "preds = outputs.predictions.argmax(-1)\n",
    "labels = outputs.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       1.00      0.83      0.91        30\n",
      "      Sports       0.91      1.00      0.95        21\n",
      "    Business       0.53      0.83      0.65        12\n",
      "    Sci/Tech       0.94      0.84      0.89        37\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.84      0.88      0.85       100\n",
      "weighted avg       0.90      0.87      0.88       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds, target_names=label2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
