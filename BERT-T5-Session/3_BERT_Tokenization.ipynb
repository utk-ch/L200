{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's happening behind the scene of Tokenization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the model and tokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the input\n",
    "inputs = tokenizer(\"We liked the embedders, we were okay with encoder decoders, but we love the transformers.\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2057,  4669,  1996,  7861,  8270, 13375,  1010,  2057,  2020,\n",
       "          3100,  2007,  4372, 16044,  2099, 21933, 13375,  1010,  2021,  2057,\n",
       "          2293,  1996, 19081,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did we get from input string to these numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "- Our inputs are text. These models work with numbers, so the first thing we need to do is to convert the text inputs into numbers.\n",
    "\n",
    "- The tokenizer first tokenizes the inputs. This means that it splits the input string in words (or part of words, punctuation symbols, etc.) that are called tokens.\n",
    "\n",
    "- Then, it converts these tokens into numbers. Each token is associated to an input ID, which is an integer. The same token will always be associated to the same ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'liked', '😊', 'the', 'embedders', ',', 'we', 'were', 'okay', 'with', 'en', '##code', '##r', 'deco', '##ders', ',', 'but', 'we', 'love', 'the', 'transformers', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_str = tokenizer.tokenize(\"We liked 😊 the embedders, we were okay with encoder decoders, but we love the transformers.\")\n",
    "print(tokenized_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2057, 4669, 1996, 7861, 8270, 13375, 1010, 2057, 2020, 3100, 2007, 4372, 16044, 2099, 21933, 13375, 1010, 2021, 2057, 2293, 1996, 19081, 1012]\n"
     ]
    }
   ],
   "source": [
    "tokenized_inp_id = tokenizer.convert_tokens_to_ids(tokenized_str)\n",
    "print(tokenized_inp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', '[SEP]', '[PAD]', '[MASK]', '[UNK]')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token, tokenizer.mask_token, tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 102, 0, 103)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id, tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2057, 4669, 1996, 7861, 8270, 13375, 1010, 2057, 2020, 3100, 2007, 4372, 16044, 2099, 21933, 13375, 1010, 2021, 2057, 2293, 1996, 19081, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "tokenized_inp_id = [tokenizer.cls_token_id] + tokenized_inp_id + [tokenizer.sep_token_id]\n",
    "print(tokenized_inp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] we liked the embedders, we were okay with encoder decoders, but we love the transformers. [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_inp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']==torch.tensor(tokenized_inp_id).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_batch2 = tokenizer([\"this summer is killing me\", \"me too\"], padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2621, 2003, 4288, 2033,  102],\n",
       "        [ 101, 2033, 2205,  102,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_batch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_batch2['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " 'liked',\n",
       " 'the',\n",
       " 'em',\n",
       " '##bed',\n",
       " '##ders',\n",
       " ',',\n",
       " 'we',\n",
       " 'were',\n",
       " 'okay',\n",
       " 'with',\n",
       " 'en',\n",
       " '##code',\n",
       " '##r',\n",
       " 'deco',\n",
       " '##ders',\n",
       " ',',\n",
       " 'but',\n",
       " 'we',\n",
       " 'love',\n",
       " 'the',\n",
       " 'transformers',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"We liked the embedders, we were okay with encoder decoders, but we love the transformers.\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did it decide to split some words and not others?\n",
    "\n",
    "- During training the model encountered some words from the training dataset. From those words it creates a vocabulary with which it can work with.\n",
    "\n",
    "- If every encountered word is treated as a separate token, then that will lead to a very large vocabulary size, indirectly increasing the size of model.\n",
    "- To avoid this, the tokenizer uses subword tokenization, which means that it splits some words into smaller parts.\n",
    "- The tokenizer is trained to perform these splits in a way that minimizes the vocabulary size while maintaining the ability to reconstruct the original words.\n",
    "- This is why the word \"embedders\" was split into \"em\", \"##bed\", \"##ders\".\n",
    "## How to check whether my word is entirely present in vocabulary or not?\n",
    "- The tokenizer has a method called get_vocab() that returns the vocabulary of the tokenizer. You can use it to check if a word is in the vocabulary or not.\n",
    "\n",
    "- For instance, tokenizer.get_vocab().get(\"embedders\") will return None, while tokenizer.get_vocab().get(\"embed\") will return a number.\n",
    "\n",
    "BERT uses WordPiece tokenization, which means that if a word is not in the vocabulary, it will be split into subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "19081\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.get_vocab().get(\"embedders\"))\n",
    "\n",
    "print(tokenizer.get_vocab().get(\"transformers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30523"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##38': 22025,\n",
       " 'collar': 9127,\n",
       " '##ising': 9355,\n",
       " 'tribes': 6946,\n",
       " 'ki': 11382,\n",
       " 'holiday': 6209,\n",
       " 'oppressive': 28558,\n",
       " 'corps': 3650,\n",
       " 'hop': 6154,\n",
       " '##va': 3567,\n",
       " '##হ': 29913,\n",
       " '##rm': 10867,\n",
       " 'benches': 19571,\n",
       " '華': 1942,\n",
       " 'jacket': 6598,\n",
       " '##vita': 28403,\n",
       " 'sustainable': 9084,\n",
       " 'ns': 24978,\n",
       " 'printing': 8021,\n",
       " '##cula': 19879,\n",
       " 'prc': 26141,\n",
       " 'opposes': 29158,\n",
       " '##dles': 27822,\n",
       " 'everyday': 10126,\n",
       " '##)': 29620,\n",
       " 'broadcasters': 18706,\n",
       " 'publishers': 8544,\n",
       " 'rune': 23276,\n",
       " 'specimen': 11375,\n",
       " '[unused432]': 437,\n",
       " 'received': 2363,\n",
       " 'several': 2195,\n",
       " 'nouns': 19211,\n",
       " 'dresses': 14464,\n",
       " 'expressed': 5228,\n",
       " 'dealers': 16743,\n",
       " 'connor': 6720,\n",
       " 'odor': 19255,\n",
       " 'books': 2808,\n",
       " 'netball': 25034,\n",
       " 'ා': 1408,\n",
       " 'contradiction': 26917,\n",
       " '[unused533]': 538,\n",
       " 'spaces': 7258,\n",
       " '##bino': 21891,\n",
       " '##eral': 21673,\n",
       " 'lunged': 17755,\n",
       " 'basal': 15191,\n",
       " 'harmonica': 16527,\n",
       " '##son': 3385,\n",
       " 'schubert': 24645,\n",
       " 'magdalene': 26890,\n",
       " '##ath': 8988,\n",
       " '##ulu': 20391,\n",
       " '##cton': 28312,\n",
       " 'competes': 14190,\n",
       " 'william': 2520,\n",
       " 'cork': 8513,\n",
       " 'consisted': 5031,\n",
       " 'lease': 10084,\n",
       " 'interpret': 17841,\n",
       " '鈴': 1965,\n",
       " 'miss': 3335,\n",
       " 'concept': 4145,\n",
       " 'footballers': 27784,\n",
       " '##gni': 29076,\n",
       " '##γ': 29721,\n",
       " 'bulky': 27446,\n",
       " 'canning': 24549,\n",
       " 'relocating': 26811,\n",
       " 'staged': 9813,\n",
       " 'pronunciation': 15498,\n",
       " 'hangul': 19051,\n",
       " 'hendrix': 20645,\n",
       " 'tally': 19552,\n",
       " 'updated': 7172,\n",
       " '##chy': 11714,\n",
       " '##oin': 28765,\n",
       " 'tbilisi': 22406,\n",
       " '##”': 30059,\n",
       " 'dirt': 6900,\n",
       " 'arcadia': 25178,\n",
       " 'spectacle': 21177,\n",
       " 'mystery': 6547,\n",
       " 'dull': 10634,\n",
       " 'habsburg': 17486,\n",
       " 'at': 2012,\n",
       " 'alleged': 6884,\n",
       " 'penetration': 20015,\n",
       " 'curse': 8364,\n",
       " 'christina': 12657,\n",
       " 'provides': 3640,\n",
       " 'eponymous': 15248,\n",
       " 'shetland': 25552,\n",
       " 'reid': 9027,\n",
       " 'networks': 6125,\n",
       " 'shock': 5213,\n",
       " 'showed': 3662,\n",
       " 'cat': 4937,\n",
       " '[unused331]': 336,\n",
       " 'dissolved': 8314,\n",
       " 'duffy': 17971,\n",
       " 'camel': 19130,\n",
       " 'nostalgia': 26968,\n",
       " '[unused441]': 446,\n",
       " 'eighteen': 7763,\n",
       " 'ramps': 24943,\n",
       " '49': 4749,\n",
       " '1886': 6929,\n",
       " '##lizer': 28863,\n",
       " 'lovely': 8403,\n",
       " 'assuming': 10262,\n",
       " 'supply': 4425,\n",
       " 'candidate': 4018,\n",
       " 'isn': 3475,\n",
       " 'cultivated': 13237,\n",
       " 'percent': 3867,\n",
       " '##oya': 18232,\n",
       " 'decreased': 10548,\n",
       " 'quite': 3243,\n",
       " 'gorilla': 23526,\n",
       " '1200': 14840,\n",
       " 'body': 2303,\n",
       " 'yarn': 27158,\n",
       " 'designate': 24414,\n",
       " '##ᴵ': 30029,\n",
       " '古': 1789,\n",
       " '##µ': 29659,\n",
       " '65': 3515,\n",
       " 'inspecting': 29508,\n",
       " 'tia': 27339,\n",
       " 'governmental': 10605,\n",
       " 'て': 1665,\n",
       " 'wide': 2898,\n",
       " '##eland': 25689,\n",
       " 'worsened': 27622,\n",
       " 'bs': 18667,\n",
       " 'bind': 14187,\n",
       " 'amalgamation': 21968,\n",
       " 'folklore': 13104,\n",
       " 'global': 3795,\n",
       " 'shops': 7340,\n",
       " '##bility': 8553,\n",
       " 'vp': 21210,\n",
       " '##dington': 21504,\n",
       " '##kker': 23793,\n",
       " 'chicks': 20649,\n",
       " '##hm': 14227,\n",
       " 'unlimited': 14668,\n",
       " 'classified': 6219,\n",
       " 'reclaim': 24104,\n",
       " 'fin': 10346,\n",
       " 'heiress': 20020,\n",
       " 'reddish': 14182,\n",
       " 'brad': 8226,\n",
       " '##ła': 22972,\n",
       " '##eux': 20860,\n",
       " '##chase': 26300,\n",
       " 'interested': 4699,\n",
       " 'brenda': 15507,\n",
       " 'massey': 21402,\n",
       " 'swings': 18755,\n",
       " 'townland': 23635,\n",
       " 'rushes': 18545,\n",
       " 'jiang': 20613,\n",
       " 'khalid': 21828,\n",
       " 'spaniards': 20999,\n",
       " '##ow': 5004,\n",
       " 'baltimore': 6222,\n",
       " '##oulos': 28262,\n",
       " 'patty': 17798,\n",
       " '##hole': 11484,\n",
       " '##貴': 30479,\n",
       " 'backside': 25065,\n",
       " '##osomal': 27642,\n",
       " 'extinct': 8548,\n",
       " '##eter': 15141,\n",
       " 'apical': 29197,\n",
       " 'illustrates': 24899,\n",
       " 'sidewalk': 11996,\n",
       " 'resorts': 16511,\n",
       " 'mahmoud': 27278,\n",
       " '##☆': 30148,\n",
       " 'superman': 10646,\n",
       " 'dennis': 6877,\n",
       " '##card': 11522,\n",
       " 'northumberland': 16205,\n",
       " 'dustin': 24337,\n",
       " '##nsed': 27730,\n",
       " '##介': 30285,\n",
       " 'theaters': 12370,\n",
       " 'cartoons': 13941,\n",
       " 'awakening': 16936,\n",
       " 'gan': 25957,\n",
       " 'glared': 9400,\n",
       " '2017': 2418,\n",
       " '貝': 1952,\n",
       " 'artifacts': 10471,\n",
       " 'prosperous': 18241,\n",
       " 'ali': 4862,\n",
       " '##rit': 14778,\n",
       " '##glio': 29480,\n",
       " 'pension': 11550,\n",
       " '##dion': 29573,\n",
       " '##osition': 19234,\n",
       " '##ivo': 20984,\n",
       " 'hanna': 10579,\n",
       " '##>': 29631,\n",
       " 'romantic': 6298,\n",
       " 'necessitated': 29611,\n",
       " 'long': 2146,\n",
       " 'westminster': 9434,\n",
       " 'manufacturers': 8712,\n",
       " 'his': 2010,\n",
       " '##metry': 24327,\n",
       " 'unlawful': 22300,\n",
       " 'antagonist': 17379,\n",
       " '##ß': 19310,\n",
       " 'charles': 2798,\n",
       " '##riation': 18769,\n",
       " 'dollars': 6363,\n",
       " 'metro': 6005,\n",
       " 'isle': 8842,\n",
       " 'indirect': 14958,\n",
       " 'infrastructure': 6502,\n",
       " 'myths': 17218,\n",
       " 'automotive': 12945,\n",
       " 'merchant': 6432,\n",
       " '[unused179]': 184,\n",
       " 'fl': 13109,\n",
       " '##going': 26966,\n",
       " '##most': 11800,\n",
       " 'grasping': 20854,\n",
       " 'serene': 25388,\n",
       " 'shiva': 12535,\n",
       " '[unused718]': 723,\n",
       " '##ried': 11998,\n",
       " 'baldwin': 10970,\n",
       " '##rma': 17830,\n",
       " 'sabah': 22515,\n",
       " '3rd': 3822,\n",
       " 'exclusive': 7262,\n",
       " 'then': 2059,\n",
       " '##yu': 10513,\n",
       " '##น': 29949,\n",
       " 'suffrage': 15178,\n",
       " 'texas': 3146,\n",
       " 'missed': 4771,\n",
       " 'liquor': 13207,\n",
       " 'flour': 13724,\n",
       " 'frontier': 8880,\n",
       " '1766': 21410,\n",
       " 'taxa': 23726,\n",
       " 'polish': 3907,\n",
       " 'prayer': 7083,\n",
       " '##hammer': 19742,\n",
       " '[unused44]': 45,\n",
       " 'limited': 3132,\n",
       " 'finest': 10418,\n",
       " 'fi': 10882,\n",
       " 'voyage': 8774,\n",
       " 'enforced': 16348,\n",
       " 'sci': 16596,\n",
       " 'dime': 27211,\n",
       " '##陳': 30498,\n",
       " 'laurent': 14718,\n",
       " 'extinction': 14446,\n",
       " 'initially': 3322,\n",
       " 'य': 1332,\n",
       " 'orient': 16865,\n",
       " 'worst': 5409,\n",
       " '##sol': 19454,\n",
       " 'sign': 3696,\n",
       " 'whistled': 26265,\n",
       " 'extended': 3668,\n",
       " 'grassroots': 23299,\n",
       " '1989': 2960,\n",
       " 'loaned': 13190,\n",
       " '##sir': 29481,\n",
       " 'ragged': 14202,\n",
       " 'spectra': 29237,\n",
       " 'adapted': 5967,\n",
       " '330': 14210,\n",
       " 'piers': 16067,\n",
       " '##af': 10354,\n",
       " 'ᵥ': 1510,\n",
       " 'sweetheart': 12074,\n",
       " 'proving': 13946,\n",
       " '##信': 30293,\n",
       " 'alzheimer': 21901,\n",
       " 'bach': 10384,\n",
       " 'verbal': 12064,\n",
       " 'floors': 8158,\n",
       " 'accessories': 16611,\n",
       " 'edwin': 10049,\n",
       " 'seminar': 18014,\n",
       " '##holz': 28094,\n",
       " 'microscope': 24635,\n",
       " 'stephan': 15963,\n",
       " '##ctuated': 25638,\n",
       " 'scoring': 4577,\n",
       " 'natalie': 10829,\n",
       " 'wynn': 25328,\n",
       " '[unused572]': 577,\n",
       " 'palermo': 18705,\n",
       " 'khalifa': 27925,\n",
       " '##agne': 25440,\n",
       " 'dual': 7037,\n",
       " 'dec': 11703,\n",
       " 'sticks': 12668,\n",
       " 'shelby': 15294,\n",
       " '正': 1888,\n",
       " 'flute': 8928,\n",
       " 'pictures': 4620,\n",
       " 'mobility': 12969,\n",
       " 'constituted': 11846,\n",
       " 'improvement': 7620,\n",
       " 'linen': 17517,\n",
       " '##kumar': 18494,\n",
       " 'ncaa': 5803,\n",
       " '##rill': 24714,\n",
       " '##lash': 27067,\n",
       " 'kung': 18577,\n",
       " 'mandela': 26887,\n",
       " 'pour': 10364,\n",
       " '70': 3963,\n",
       " '[unused471]': 476,\n",
       " 'curious': 8025,\n",
       " 'calves': 28023,\n",
       " 'somebody': 8307,\n",
       " 'rumbled': 22257,\n",
       " '##hani': 23573,\n",
       " 'becker': 15309,\n",
       " '##48': 18139,\n",
       " 'prevent': 4652,\n",
       " 'takeoff': 19744,\n",
       " 'consequence': 9509,\n",
       " 'lowest': 7290,\n",
       " 'anxious': 11480,\n",
       " '##ᄊ': 29998,\n",
       " 'wellington': 8409,\n",
       " '##mans': 15154,\n",
       " 'patient': 5776,\n",
       " 'montane': 21704,\n",
       " '278': 24709,\n",
       " 'turnpike': 17116,\n",
       " 'う': 1648,\n",
       " '##zel': 12638,\n",
       " '##oman': 20778,\n",
       " '##ᄅ': 29994,\n",
       " '[unused885]': 890,\n",
       " 'announcing': 13856,\n",
       " '[unused653]': 658,\n",
       " 'innovation': 8144,\n",
       " 'checkpoint': 26520,\n",
       " '##hausen': 13062,\n",
       " 'speech': 4613,\n",
       " 'levi': 11902,\n",
       " '##dong': 17679,\n",
       " 'hertfordshire': 18889,\n",
       " '[unused525]': 530,\n",
       " 'kitchens': 26051,\n",
       " '[unused880]': 885,\n",
       " 'muller': 12304,\n",
       " 'education': 2495,\n",
       " 'mankind': 14938,\n",
       " 'cancers': 25409,\n",
       " 'flavors': 26389,\n",
       " '##reate': 29313,\n",
       " 'des': 4078,\n",
       " '##fixed': 23901,\n",
       " 'part': 2112,\n",
       " '##rp': 14536,\n",
       " 'cad': 28353,\n",
       " '[unused825]': 830,\n",
       " 'copenhagen': 9664,\n",
       " 'practice': 3218,\n",
       " 'implementations': 24977,\n",
       " 'ge': 16216,\n",
       " 'fibers': 16662,\n",
       " '##not': 17048,\n",
       " 'dungeon': 16633,\n",
       " 'federico': 20493,\n",
       " 'combat': 4337,\n",
       " 'congressional': 7740,\n",
       " 'astro': 28625,\n",
       " 'issues': 3314,\n",
       " '##power': 11452,\n",
       " 'regaining': 28657,\n",
       " '##oese': 23379,\n",
       " 'hurst': 26405,\n",
       " 'punishment': 7750,\n",
       " 'labyrinth': 24239,\n",
       " 'bosnian': 16163,\n",
       " '##standing': 24911,\n",
       " 'frederick': 5406,\n",
       " 'wives': 10403,\n",
       " '##η': 24824,\n",
       " 'gothenburg': 22836,\n",
       " 'ᅡ': 1470,\n",
       " 'helicopter': 7739,\n",
       " 'cambrian': 29228,\n",
       " 'rebel': 8443,\n",
       " '##lock': 7878,\n",
       " 'overthrow': 16857,\n",
       " 'leopold': 12752,\n",
       " 'obstruction': 27208,\n",
       " 'must': 2442,\n",
       " 'unconscious': 9787,\n",
       " 'speaking': 4092,\n",
       " '##nel': 11877,\n",
       " 'idf': 24011,\n",
       " '##kovich': 28195,\n",
       " 'contemporaries': 16682,\n",
       " '[unused819]': 824,\n",
       " 'champaign': 28843,\n",
       " '##ter': 3334,\n",
       " 'normal': 3671,\n",
       " 'conservative': 4603,\n",
       " 'oldham': 18285,\n",
       " 'illegitimate': 18102,\n",
       " '##は': 30198,\n",
       " 'alright': 10303,\n",
       " 'defaulted': 17265,\n",
       " 'supremacy': 22006,\n",
       " 'beforehand': 25828,\n",
       " 'signal': 4742,\n",
       " 'perhaps': 3383,\n",
       " 'actions': 4506,\n",
       " 'sweet': 4086,\n",
       " 'ɨ': 1118,\n",
       " 'answered': 4660,\n",
       " 'folks': 12455,\n",
       " 'entertainer': 21751,\n",
       " 'bandits': 19088,\n",
       " '##gging': 12588,\n",
       " 'ware': 16283,\n",
       " 'vishnu': 17647,\n",
       " 'izzy': 16699,\n",
       " '##position': 26994,\n",
       " 'ste': 26261,\n",
       " 'escorted': 13127,\n",
       " 'orbital': 13943,\n",
       " 'irvine': 16272,\n",
       " 'faso': 22773,\n",
       " 'elevator': 7764,\n",
       " 'testing': 5604,\n",
       " '##bered': 22408,\n",
       " 'juicy': 28900,\n",
       " 'succeeding': 13034,\n",
       " 'translated': 5421,\n",
       " 'nicknamed': 9919,\n",
       " 'pereira': 23857,\n",
       " '##ead': 13775,\n",
       " 'densely': 19441,\n",
       " 'academy': 2914,\n",
       " 'sampson': 22041,\n",
       " '[unused126]': 131,\n",
       " '##quist': 18331,\n",
       " 'rat': 9350,\n",
       " 'trusting': 19836,\n",
       " 'deco': 21933,\n",
       " 'bent': 6260,\n",
       " 'sachs': 22818,\n",
       " '##broken': 29162,\n",
       " 'subspecies': 11056,\n",
       " 'integer': 16109,\n",
       " 'insisted': 7278,\n",
       " '1740': 21757,\n",
       " 'ı': 1104,\n",
       " 'ieee': 15368,\n",
       " 'idiot': 10041,\n",
       " '##ら': 30211,\n",
       " 'bearing': 7682,\n",
       " 'wild': 3748,\n",
       " 'performing': 4488,\n",
       " 'runner': 5479,\n",
       " 'shed': 8328,\n",
       " '##tag': 15900,\n",
       " 'landslide': 20148,\n",
       " 'captains': 15755,\n",
       " 'thorpe': 20249,\n",
       " 'tugged': 10621,\n",
       " 'hove': 25215,\n",
       " 'ioc': 25941,\n",
       " '##eous': 14769,\n",
       " 'headlines': 19377,\n",
       " 'recreational': 10517,\n",
       " 'absence': 6438,\n",
       " 'chatter': 24691,\n",
       " 'interference': 11099,\n",
       " 'ruse': 26307,\n",
       " 'shredded': 29022,\n",
       " '##mba': 11201,\n",
       " '##liche': 27412,\n",
       " 'yu': 9805,\n",
       " 'confirm': 12210,\n",
       " 'vanuatu': 27625,\n",
       " 'nathan': 7150,\n",
       " 'rodents': 28156,\n",
       " 'felipe': 17095,\n",
       " '1950s': 4856,\n",
       " 'oriental': 11481,\n",
       " 'uncles': 27328,\n",
       " 'upstream': 13909,\n",
       " 'film': 2143,\n",
       " 'dominic': 11282,\n",
       " 'row': 5216,\n",
       " 'biting': 12344,\n",
       " 'encompasses': 13974,\n",
       " 'invading': 17657,\n",
       " 'costumes': 12703,\n",
       " '##dc': 16409,\n",
       " 'swelling': 18348,\n",
       " 'nationwide': 9053,\n",
       " '[unused677]': 682,\n",
       " 'grave': 6542,\n",
       " 'trench': 14185,\n",
       " 'fluids': 20989,\n",
       " 'guns': 4409,\n",
       " 'embarrassment': 14325,\n",
       " 'arbitrary': 15275,\n",
       " 'musee': 18070,\n",
       " '##rich': 13149,\n",
       " '##mara': 28225,\n",
       " 'conflicts': 9755,\n",
       " 'bloomington': 26372,\n",
       " 'feather': 15550,\n",
       " 'jobs': 5841,\n",
       " 'bayer': 26367,\n",
       " 'tobacco': 9098,\n",
       " '##hey': 14844,\n",
       " '##秋': 30455,\n",
       " 'device': 5080,\n",
       " 'aka': 9875,\n",
       " 'gloria': 10778,\n",
       " 'jae': 22770,\n",
       " '##hana': 15788,\n",
       " 'causeway': 23336,\n",
       " 'forceful': 28552,\n",
       " 'advocate': 8175,\n",
       " 'walt': 10598,\n",
       " 'sermon': 18408,\n",
       " 'replacing': 6419,\n",
       " 'silk': 6953,\n",
       " 'wow': 10166,\n",
       " '##lined': 18194,\n",
       " 'awareness': 7073,\n",
       " 'nation': 3842,\n",
       " '74': 6356,\n",
       " 'artwork': 8266,\n",
       " 'accommodate': 8752,\n",
       " 'advances': 9849,\n",
       " 'ப': 1388,\n",
       " '##rte': 19731,\n",
       " '211': 19235,\n",
       " 'statements': 8635,\n",
       " '##imate': 21499,\n",
       " 'tyre': 21904,\n",
       " 'antigua': 26023,\n",
       " 'outset': 26674,\n",
       " 'robbie': 12289,\n",
       " 'texans': 23246,\n",
       " 'undisclosed': 18206,\n",
       " '##chan': 14856,\n",
       " 'contrast': 5688,\n",
       " 'probability': 9723,\n",
       " 'except': 3272,\n",
       " 'duluth': 28218,\n",
       " 'utmost': 27917,\n",
       " 'arresting': 28427,\n",
       " 'hiking': 13039,\n",
       " '##18': 15136,\n",
       " 'attorneys': 16214,\n",
       " '##×': 26306,\n",
       " '##rew': 15603,\n",
       " 'gateway': 11909,\n",
       " 'minas': 21750,\n",
       " '299': 25926,\n",
       " 'bored': 11471,\n",
       " 'ᅭ': 1477,\n",
       " 'baxter': 14664,\n",
       " 'scott': 3660,\n",
       " 'illuminated': 14640,\n",
       " 'pinched': 18521,\n",
       " 'folder': 19622,\n",
       " 'romanesque': 17135,\n",
       " '##。': 30162,\n",
       " 'wince': 29585,\n",
       " 'telegram': 23921,\n",
       " '##iques': 19516,\n",
       " 'hoffmann': 24437,\n",
       " 'syndicated': 13889,\n",
       " 'logging': 15899,\n",
       " 'woodstock': 21028,\n",
       " '##iring': 24771,\n",
       " 'onward': 15834,\n",
       " 'confusion': 6724,\n",
       " 'polynomial': 17505,\n",
       " 'emergencies': 26360,\n",
       " 'advancing': 10787,\n",
       " 'moisture': 14098,\n",
       " '##dna': 28911,\n",
       " 'engulfed': 24692,\n",
       " 'scarborough': 18603,\n",
       " 'benoit': 21721,\n",
       " 'denounced': 17787,\n",
       " 'extra': 4469,\n",
       " '##bach': 7693,\n",
       " 'flavour': 28126,\n",
       " '##ह': 29875,\n",
       " '##მ': 29984,\n",
       " 'carlos': 5828,\n",
       " 'puts': 8509,\n",
       " 'toys': 10899,\n",
       " 'maid': 10850,\n",
       " 'solidarity': 14657,\n",
       " '318': 27003,\n",
       " 'deeds': 15616,\n",
       " 'hardened': 15015,\n",
       " 'sunshine': 9609,\n",
       " 'curved': 9203,\n",
       " 'hating': 22650,\n",
       " 'calvert': 24800,\n",
       " 'specifies': 27171,\n",
       " 'victims': 5694,\n",
       " '[unused534]': 539,\n",
       " 'strategies': 9942,\n",
       " '501': 16202,\n",
       " '[unused212]': 217,\n",
       " 'teddy': 11389,\n",
       " '##pid': 23267,\n",
       " 'bite': 6805,\n",
       " 'proposing': 21991,\n",
       " 'cdc': 26629,\n",
       " 'metaphor': 19240,\n",
       " '##board': 6277,\n",
       " 'dt': 26718,\n",
       " 'collaborative': 12317,\n",
       " '##7th': 27506,\n",
       " 'support': 2490,\n",
       " 'serbia': 7238,\n",
       " 'intervening': 26623,\n",
       " 'functioning': 12285,\n",
       " 'outdoors': 19350,\n",
       " 'revived': 10570,\n",
       " 'watts': 11042,\n",
       " 'nationalists': 17934,\n",
       " 'qc': 25196,\n",
       " 'charming': 11951,\n",
       " 'button': 6462,\n",
       " '##jon': 14339,\n",
       " '229': 22777,\n",
       " 'iss': 26354,\n",
       " '##idi': 28173,\n",
       " 'didn': 2134,\n",
       " 'uganda': 10031,\n",
       " 'otter': 22279,\n",
       " '##haven': 14650,\n",
       " '##ysis': 20960,\n",
       " '##چ': 29840,\n",
       " 'zeke': 18270,\n",
       " 'braden': 27232,\n",
       " 'fey': 23864,\n",
       " 'tyrant': 26508,\n",
       " 'haley': 16624,\n",
       " 'athena': 21880,\n",
       " 'registry': 15584,\n",
       " 'phrase': 7655,\n",
       " 'metacritic': 14476,\n",
       " 'ferris': 23202,\n",
       " 'カ': 1700,\n",
       " '安': 1820,\n",
       " 'wei': 11417,\n",
       " 'mod': 16913,\n",
       " 'tools': 5906,\n",
       " '##elia': 13902,\n",
       " 'ம': 1389,\n",
       " 'self': 2969,\n",
       " 'information': 2592,\n",
       " '##dle': 10362,\n",
       " 'regeneration': 20045,\n",
       " '1762': 20827,\n",
       " '[unused589]': 594,\n",
       " 'measurement': 10903,\n",
       " 'connie': 16560,\n",
       " 'reconcile': 21063,\n",
       " 'pilgrim': 21214,\n",
       " '##ия': 23483,\n",
       " 'extras': 26279,\n",
       " 'hissing': 26386,\n",
       " 'ata': 29533,\n",
       " 'williamson': 14333,\n",
       " '##»': 29663,\n",
       " 'gland': 25320,\n",
       " 'italian': 3059,\n",
       " 'incorrect': 16542,\n",
       " 'tavi': 24283,\n",
       " '##coe': 16288,\n",
       " 'wight': 20945,\n",
       " 'somme': 25158,\n",
       " '##kken': 24192,\n",
       " 'dynasties': 23014,\n",
       " 'final': 2345,\n",
       " 'dragon': 5202,\n",
       " 'okinawa': 15052,\n",
       " 'nicely': 19957,\n",
       " 'complimented': 27175,\n",
       " 'restart': 23818,\n",
       " 'bulb': 20581,\n",
       " 'cop': 8872,\n",
       " 'bihar': 16178,\n",
       " '##ifiers': 28295,\n",
       " 'palatine': 22202,\n",
       " 'sailor': 11803,\n",
       " '[unused96]': 97,\n",
       " 'tear': 7697,\n",
       " 'wigan': 15598,\n",
       " '##沢': 30424,\n",
       " '[unused935]': 940,\n",
       " '##linson': 25051,\n",
       " 'eel': 24315,\n",
       " 'empowered': 26480,\n",
       " '##miento': 28883,\n",
       " 'hates': 16424,\n",
       " 'jump': 5376,\n",
       " 'anxiously': 23403,\n",
       " 'heavens': 17223,\n",
       " 'dominance': 13811,\n",
       " 'dart': 14957,\n",
       " '[unused317]': 322,\n",
       " 'schmidt': 12940,\n",
       " '##cy': 5666,\n",
       " '##ashi': 12914,\n",
       " 'prolonged': 15330,\n",
       " '##brand': 23544,\n",
       " 'werewolf': 12797,\n",
       " 'merging': 16468,\n",
       " '##erson': 18617,\n",
       " 'reuben': 17294,\n",
       " 'cha': 15775,\n",
       " 'azerbaijani': 18325,\n",
       " 'magnitude': 10194,\n",
       " 'appliances': 22449,\n",
       " '##tort': 25485,\n",
       " 'former': 2280,\n",
       " 'storey': 11676,\n",
       " 'packing': 14743,\n",
       " 'phil': 6316,\n",
       " '##sen': 5054,\n",
       " 'asshole': 22052,\n",
       " 'facebook': 9130,\n",
       " 'witness': 7409,\n",
       " 'marxist': 15511,\n",
       " '↑': 1584,\n",
       " 'barred': 15605,\n",
       " 'stops': 6762,\n",
       " '##tropical': 25528,\n",
       " '##l': 2140,\n",
       " 'rouen': 27030,\n",
       " 'oakley': 28876,\n",
       " 'rejoin': 25261,\n",
       " 'unemployment': 12163,\n",
       " 'pep': 27233,\n",
       " 'portraying': 17274,\n",
       " 'lighthouse': 10171,\n",
       " '129': 14378,\n",
       " 'inversion': 28527,\n",
       " 'service': 2326,\n",
       " 'repeating': 15192,\n",
       " '[unused340]': 345,\n",
       " 'ʾ': 1147,\n",
       " 'cao': 12966,\n",
       " '##ulating': 10924,\n",
       " 'falls': 4212,\n",
       " 'moan': 13673,\n",
       " 'dizzy': 14849,\n",
       " 'earnest': 17300,\n",
       " 'insider': 25297,\n",
       " 'persuaded': 11766,\n",
       " 'courtney': 14139,\n",
       " 'kant': 26044,\n",
       " '##powered': 27267,\n",
       " 'crested': 25413,\n",
       " 'williamsburg': 26366,\n",
       " 'commencement': 20561,\n",
       " 'japanese': 2887,\n",
       " 'audition': 14597,\n",
       " '##uts': 16446,\n",
       " '##cked': 18141,\n",
       " 'tumbled': 18303,\n",
       " '##nder': 11563,\n",
       " 'commonwealth': 5663,\n",
       " 'pupil': 11136,\n",
       " '##olved': 16116,\n",
       " 'descends': 23328,\n",
       " 'dunedin': 22020,\n",
       " '##wehr': 27156,\n",
       " 'table': 2795,\n",
       " '220': 10545,\n",
       " 'gently': 5251,\n",
       " '##ian': 2937,\n",
       " 'millions': 8817,\n",
       " 'blindly': 25734,\n",
       " 'fitzpatrick': 26249,\n",
       " '##amy': 24079,\n",
       " 'swiped': 24452,\n",
       " 'earn': 7796,\n",
       " 'comparative': 12596,\n",
       " 'は': 1672,\n",
       " 'asleep': 6680,\n",
       " 'kc': 21117,\n",
       " 'discussed': 6936,\n",
       " 'lithuanian': 10333,\n",
       " '##le': 2571,\n",
       " 'unavailable': 20165,\n",
       " '##yce': 29297,\n",
       " '[unused360]': 365,\n",
       " 'ง': 1410,\n",
       " 'vicious': 13925,\n",
       " 'envisioned': 18035,\n",
       " '##oir': 21165,\n",
       " 'umm': 26114,\n",
       " '##lden': 28476,\n",
       " 'deborah': 15555,\n",
       " '##bla': 28522,\n",
       " 'mmm': 25391,\n",
       " 'mentor': 10779,\n",
       " '[unused762]': 767,\n",
       " '年': 1840,\n",
       " 'membership': 5779,\n",
       " 'inherent': 16112,\n",
       " 'prop': 17678,\n",
       " 'shipbuilding': 16802,\n",
       " 'spice': 17688,\n",
       " 'pussy': 22418,\n",
       " '##iensis': 27806,\n",
       " 'nonfiction': 25753,\n",
       " 'angie': 14835,\n",
       " 'homicide': 18268,\n",
       " 'jessica': 8201,\n",
       " 'condemn': 28887,\n",
       " 'ang': 17076,\n",
       " 'magnetic': 8060,\n",
       " 'discontent': 27648,\n",
       " 'chrysler': 17714,\n",
       " 'blasts': 25829,\n",
       " 'chemicals': 12141,\n",
       " '##is': 2483,\n",
       " 'to': 2000,\n",
       " 'stared': 3592,\n",
       " 'traps': 16735,\n",
       " '##ﬁ': 30510,\n",
       " '##rky': 15952,\n",
       " 'professorship': 22661,\n",
       " 'kunst': 28145,\n",
       " 'carlo': 9758,\n",
       " 'ranked': 4396,\n",
       " 'pill': 17357,\n",
       " 'little': 2210,\n",
       " 'bb': 22861,\n",
       " 'orson': 25026,\n",
       " '##eh': 11106,\n",
       " 'deputies': 11964,\n",
       " 'icc': 16461,\n",
       " '八': 1771,\n",
       " 'qur': 23183,\n",
       " 'surrey': 9948,\n",
       " 'shortage': 15843,\n",
       " 'martinez': 10337,\n",
       " 'infectious': 16514,\n",
       " 'client': 7396,\n",
       " 'observatory': 9970,\n",
       " 'assent': 27195,\n",
       " 'cartoonist': 19659,\n",
       " 'applause': 20737,\n",
       " '##dda': 25062,\n",
       " '##aga': 16098,\n",
       " '##iidae': 15648,\n",
       " 'wouldn': 2876,\n",
       " '##wes': 18192,\n",
       " 'cuts': 7659,\n",
       " '##kir': 23630,\n",
       " 'guards': 4932,\n",
       " 'া': 1378,\n",
       " 'dramas': 16547,\n",
       " 'burundi': 28836,\n",
       " 'cruel': 10311,\n",
       " 'scarlet': 11862,\n",
       " 'worthless': 22692,\n",
       " 'provoke': 27895,\n",
       " '##ogen': 23924,\n",
       " 'symbol': 6454,\n",
       " '660': 20982,\n",
       " 'イ': 1695,\n",
       " 'suspicion': 10928,\n",
       " 'sixteen': 7032,\n",
       " 'bop': 29432,\n",
       " '##lone': 27165,\n",
       " 'kerry': 11260,\n",
       " 'lilly': 14765,\n",
       " '##llah': 18599,\n",
       " '##ج': 29819,\n",
       " 'concentrations': 14061,\n",
       " 'rufus': 18316,\n",
       " '##vance': 21789,\n",
       " 'yearbook': 24803,\n",
       " '1626': 28818,\n",
       " '##jer': 20009,\n",
       " 'studies': 2913,\n",
       " 'pretty': 3492,\n",
       " 'clair': 17936,\n",
       " 'translation': 5449,\n",
       " 'baronet': 8693,\n",
       " 'sentinel': 16074,\n",
       " 'surpassed': 15602,\n",
       " 'tutor': 14924,\n",
       " '##間': 30495,\n",
       " 'cherokee': 13796,\n",
       " 'settle': 7392,\n",
       " 'neurological': 23130,\n",
       " 'v8': 15754,\n",
       " 'ャ': 1728,\n",
       " 'hence': 6516,\n",
       " 'capitalist': 19640,\n",
       " 'utilize': 16462,\n",
       " 'sky': 3712,\n",
       " 'assignment': 8775,\n",
       " '的': 1916,\n",
       " '##ng': 3070,\n",
       " 'enhanced': 9412,\n",
       " 'whale': 13156,\n",
       " '##tao': 28555,\n",
       " '##burg': 4645,\n",
       " 'phylogenetic': 23192,\n",
       " '##hoff': 17896,\n",
       " '##ids': 9821,\n",
       " 'bullock': 25200,\n",
       " 'ultra': 11087,\n",
       " '##sis': 6190,\n",
       " '239': 23688,\n",
       " 'lac': 18749,\n",
       " 'billings': 26124,\n",
       " 'hurts': 13403,\n",
       " 'communicating': 20888,\n",
       " 'synonymous': 22594,\n",
       " 'pac': 14397,\n",
       " 'harald': 20966,\n",
       " '##平': 30365,\n",
       " 'restaurants': 7884,\n",
       " 'rodgers': 15652,\n",
       " '##ark': 17007,\n",
       " '##安': 30346,\n",
       " 'yet': 2664,\n",
       " '井': 1754,\n",
       " 'flea': 26735,\n",
       " 'happily': 11361,\n",
       " 'footprints': 24629,\n",
       " '[unused564]': 569,\n",
       " 'semitic': 20604,\n",
       " '##§': 29650,\n",
       " 'shootout': 18297,\n",
       " 'cope': 11997,\n",
       " 'spade': 23288,\n",
       " 'rabbi': 7907,\n",
       " '47th': 28243,\n",
       " '##ila': 11733,\n",
       " 'expansion': 4935,\n",
       " 'conservatoire': 29233,\n",
       " 'sovereign': 11074,\n",
       " 'fleeing': 14070,\n",
       " 'א': 1241,\n",
       " 'daytime': 12217,\n",
       " 'encourages': 16171,\n",
       " '##ion': 3258,\n",
       " '##tical': 14656,\n",
       " 'shelves': 15475,\n",
       " '##vs': 15088,\n",
       " '##bolt': 22803,\n",
       " 'karachi': 15381,\n",
       " 'drafts': 28967,\n",
       " 'hit': 2718,\n",
       " 'csi': 22174,\n",
       " '[unused407]': 412,\n",
       " 'crude': 13587,\n",
       " 'outstretched': 21059,\n",
       " '##tip': 25101,\n",
       " 'momentum': 11071,\n",
       " 'johansson': 26447,\n",
       " '[unused159]': 164,\n",
       " '[unused654]': 659,\n",
       " 'han': 7658,\n",
       " '##nn': 10695,\n",
       " 'ж': 1186,\n",
       " '⽥': 1634,\n",
       " 'weston': 12755,\n",
       " 'exercises': 11110,\n",
       " 'thor': 15321,\n",
       " 'marital': 23143,\n",
       " 'franz': 8965,\n",
       " ...}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we add new words into tokenizer?\n",
    "\n",
    "If you want to add a new word to the vocabulary, you can use the add_tokens() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new word into tokenizer\n",
    "tokenizer.add_tokens([\"embedders\", \"😊\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab().get(\"embedders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30523"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'liked', 'the', 'embedders', ',', 'we', 'were', 'okay', 'with', 'en', '##code', '##r', 'deco', '##ders', ',', 'but', 'we', 'love', 'the', 'transformers', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_str = tokenizer.tokenize(\"We liked the embedders, we were okay with encoder decoders, but we love the transformers.\")\n",
    "print(tokenized_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
